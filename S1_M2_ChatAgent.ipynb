{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/SPE_GeoHackathon_2025/blob/dev/S1_M2_ChatAgent.ipynb)\n",
    "\n",
    "***\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by running each cell in order\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Make sure to run the environment setup cells first\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Wait for each installation to complete before proceeding\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if installations take a while - this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Environment setup\n",
    "!pip -q install langchain langchain-core langchain-community langchain-huggingface torch gradio\n",
    "!pip -q install bitsandbytes==0.46.0 transformers==4.48.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face API token\n",
    "# Retrieving the token is required to get access to HF hub\n",
    "from google.colab import userdata\n",
    "hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 01 // Module 02: First Chat Agent with LangChain\n",
    "\n",
    "In this module, we'll build our first conversational AI agent using modern LangChain. We'll create a geoscience-focused chatbot that can answer questions about geology, geophysics, and petroleum engineering concepts.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand modern LangChain fundamentals (LCEL, ChatModels, Messages)\n",
    "- Build a simple Q&A chat agent with Hugging Face models\n",
    "- Add conversational memory to maintain context\n",
    "- Create an interactive Gradio interface\n",
    "- Apply the agent to geoscience conversations\n",
    "\n",
    "## 1. Modern LangChain Basics\n",
    "\n",
    "**LangChain** has evolved significantly. Modern LangChain uses:\n",
    "- **LCEL (LangChain Expression Language)**: Declarative way to compose chains\n",
    "- **ChatModels**: Specialized for conversational AI\n",
    "- **Messages**: Structured conversation format\n",
    "- **Runnables**: Standardized interface for all components\n",
    "- **Memory**: More flexible conversation state management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setting up the Modern Language Model\n",
    "\n",
    "Let's use a modern approach with ChatModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a more conversational model\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# Create HuggingFace pipeline\n",
    "# Steps:\n",
    "# 1. Load tokenizer\n",
    "# 2. Create quantization config\n",
    "# 3. Create prompt model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", quantization_config=quant_config)\n",
    "\n",
    "# Set pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create text generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.2,\n",
    "    do_sample=True, # Sampling enables more diverse outputs\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False # The generated text will not include the prompt\n",
    ")\n",
    "\n",
    "# Create LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Wrap with ChatHuggingFace for modern interface\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating Modern Prompt Templates\n",
    "\n",
    "Modern LangChain uses ChatPromptTemplate with structured messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a system prompt for geoscience expertise\n",
    "# The system prompt sets the behavior and personality of the assistant\n",
    "system_prompt = \"\"\"\n",
    "You are Dr. GeoBot, an expert geophysicist and petroleum engineer with 20 years of experience.\n",
    "You specialize in seismic interpretation, reservoir characterization, and hydrocarbon exploration.\n",
    "\n",
    "Guidelines:\n",
    "- Provide accurate, helpful answers about geoscience topics\n",
    "- Keep responses concise but informative (2-3 sentences)\n",
    "- Use technical terms but explain them when needed\n",
    "- Focus on practical applications and formulas\n",
    "- If unsure, acknowledge limitations\n",
    "\"\"\"\n",
    "\n",
    "# Create chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Test the template\n",
    "test_question = \"What is porosity?\"\n",
    "formatted_prompt = prompt_template.format_messages(question=test_question)\n",
    "print(\"Formatted prompt:\")\n",
    "for message in formatted_prompt:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating Modern Chains with LCEL\n",
    "\n",
    "Modern LangChain uses LCEL (LangChain Expression Language) for composing chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chain using LCEL\n",
    "simple_chain = prompt_template | chat_model | StrOutputParser()\n",
    "\n",
    "# Test the chain\n",
    "print(\"=== Testing Simple Chain ===\")\n",
    "response = simple_chain.invoke({\"question\": \"What is the difference between porosity and permeability?\"})\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "full_prompt = \"\"\n",
    "for msg in formatted_prompt:\n",
    "    if msg.type == \"system\":\n",
    "        full_prompt += f\"[SYSTEM]\\n{msg.content}\\n\"\n",
    "    elif msg.type == \"human\":\n",
    "        full_prompt += f\"[USER]\\n{msg.content}\\n\"\n",
    "\n",
    "inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Stream tokens as they are generated\n",
    "model.generate(**inputs, streamer=streamer, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple geoscience questions\n",
    "test_questions = [\n",
    "    \"What is seismic resolution?\",\n",
    "    \"How do P-waves differ from S-waves?\",\n",
    "    \"What factors affect hydrocarbon migration?\"\n",
    "]\n",
    "\n",
    "print(\"=== Testing Multiple Questions ===\")\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    response = simple_chain.invoke({\"question\": question})\n",
    "    print(f\"   Answer: {response}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding Modern Conversational Memory\n",
    "\n",
    "Modern LangChain uses RunnableWithMessageHistory for conversation management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversational prompt template with history\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Create the conversational chain\n",
    "conversational_chain = conversational_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# Store for conversation histories\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Create conversational chain with memory\n",
    "conversational_with_memory = RunnableWithMessageHistory(\n",
    "    conversational_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "print(\"Conversational chain with memory created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conversational memory\n",
    "print(\"=== Testing Conversational Memory ===\")\n",
    "\n",
    "session_config = {\"configurable\": {\"session_id\": \"test_session\"}}\n",
    "\n",
    "# First question\n",
    "response1 = conversational_with_memory.invoke(\n",
    "    {\"question\": \"What is seismic inversion?\"},\n",
    "    config=session_config\n",
    ")\n",
    "print(f\"Q1: What is seismic inversion?\")\n",
    "print(f\"A1: {response1}\")\n",
    "print()\n",
    "\n",
    "# Follow-up question that refers to previous context\n",
    "response2 = conversational_with_memory.invoke(\n",
    "    {\"question\": \"What are the main types of this technique?\"},\n",
    "    config=session_config\n",
    ")\n",
    "print(f\"Q2: What are the main types of this technique?\")\n",
    "print(f\"A2: {response2}\")\n",
    "print()\n",
    "\n",
    "# Another follow-up\n",
    "response3 = conversational_with_memory.invoke(\n",
    "    {\"question\": \"Which type is most commonly used in the industry?\"},\n",
    "    config=session_config\n",
    ")\n",
    "print(f\"Q3: Which type is most commonly used in the industry?\")\n",
    "print(f\"A3: {response3}\")\n",
    "print()\n",
    "\n",
    "# Check memory content\n",
    "print(\"=== Current Memory ===\")\n",
    "history = get_session_history(\"test_session\")\n",
    "for message in history.messages:\n",
    "    print(f\"{message.type}: {message.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Modern Chat Agent Class\n",
    "\n",
    "Let's create a robust chat agent using modern LangChain patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import uuid\n",
    "\n",
    "class ModernGeoscienceChatAgent:\n",
    "    def __init__(self, chat_model):\n",
    "        self.chat_model = chat_model\n",
    "        self.store = {}\n",
    "        \n",
    "        # Enhanced system prompt\n",
    "        self.system_prompt = \"\"\"\n",
    "You are Dr. GeoBot, a friendly and knowledgeable geoscience expert specializing in:\n",
    "- Geophysics and seismic interpretation\n",
    "- Petroleum geology and reservoir engineering  \n",
    "- Well logging and formation evaluation\n",
    "- Hydrocarbon exploration and production\n",
    "- Geomechanics and drilling engineering\n",
    "\n",
    "Guidelines:\n",
    "- Provide accurate, helpful answers about geoscience topics\n",
    "- Use technical terms but explain them when needed\n",
    "- Be conversational and engaging\n",
    "- Keep responses focused and informative\n",
    "- If unsure, acknowledge limitations honestly\n",
    "- Reference previous conversation when relevant\n",
    "\"\"\"\n",
    "        \n",
    "        # Create prompt template\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "        \n",
    "        # Create chain\n",
    "        self.chain = self.prompt | self.chat_model | StrOutputParser()\n",
    "        \n",
    "        # Create conversational chain with memory\n",
    "        self.conversational_chain = RunnableWithMessageHistory(\n",
    "            self.chain,\n",
    "            self.get_session_history,\n",
    "            input_messages_key=\"question\",\n",
    "            history_messages_key=\"history\",\n",
    "        )\n",
    "    \n",
    "    def get_session_history(self, session_id: str) -> BaseChatMessageHistory:\n",
    "        if session_id not in self.store:\n",
    "            self.store[session_id] = ChatMessageHistory()\n",
    "        return self.store[session_id]\n",
    "    \n",
    "    def chat(self, question: str, session_id: str = \"default\") -> str:\n",
    "        \"\"\"Process a question and return a response\"\"\"\n",
    "        try:\n",
    "            config = {\"configurable\": {\"session_id\": session_id}}\n",
    "            response = self.conversational_chain.invoke(\n",
    "                {\"question\": question},\n",
    "                config=config\n",
    "            )\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            return f\"I apologize, but I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def clear_memory(self, session_id: str = \"default\"):\n",
    "        \"\"\"Clear conversation history for a session\"\"\"\n",
    "        if session_id in self.store:\n",
    "            self.store[session_id].clear()\n",
    "    \n",
    "    def get_history(self, session_id: str = \"default\") -> list:\n",
    "        \"\"\"Get conversation history for a session\"\"\"\n",
    "        if session_id in self.store:\n",
    "            return self.store[session_id].messages\n",
    "        return []\n",
    "    \n",
    "    def create_new_session(self) -> str:\n",
    "        \"\"\"Create a new conversation session\"\"\"\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "# Create the modern chat agent\n",
    "chat_agent = ModernGeoscienceChatAgent(chat_model)\n",
    "print(\"Modern GeoscienceChatAgent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the modern chat agent\n",
    "print(\"=== Testing Modern GeoscienceChatAgent ===\")\n",
    "\n",
    "# Test conversation\n",
    "questions = [\n",
    "    \"Hello! Can you explain what you specialize in?\",\n",
    "    \"What is the difference between conventional and unconventional reservoirs?\",\n",
    "    \"How do geophysicists use seismic data to find oil?\",\n",
    "    \"What role does well logging play in this process?\"\n",
    "]\n",
    "\n",
    "session_id = chat_agent.create_new_session()\n",
    "print(f\"Created session: {session_id[:8]}...\\n\")\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"{i}. Human: {question}\")\n",
    "    response = chat_agent.chat(question, session_id)\n",
    "    print(f\"   Dr. GeoBot: {response}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Modern Gradio Interface\n",
    "\n",
    "Let's create an improved web interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Create a new chat agent for the interface\n",
    "gradio_agent = ModernGeoscienceChatAgent(chat_model)\n",
    "\n",
    "# Global session management\n",
    "current_session = gradio_agent.create_new_session()\n",
    "\n",
    "def respond(message: str, history: List[Tuple[str, str]]) -> Tuple[str, List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Process user message and return bot response\n",
    "    \"\"\"\n",
    "    global current_session\n",
    "    \n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    # Get response from agent\n",
    "    bot_response = gradio_agent.chat(message, current_session)\n",
    "    \n",
    "    # Add to chat history\n",
    "    history.append((message, bot_response))\n",
    "    \n",
    "    return \"\", history\n",
    "\n",
    "def clear_conversation() -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Clear conversation history and start new session\n",
    "    \"\"\"\n",
    "    global current_session\n",
    "    gradio_agent.clear_memory(current_session)\n",
    "    current_session = gradio_agent.create_new_session()\n",
    "    return []\n",
    "\n",
    "def load_example(example: str) -> str:\n",
    "    \"\"\"\n",
    "    Load example question into the textbox\n",
    "    \"\"\"\n",
    "    return example\n",
    "\n",
    "# Create modern Gradio interface\n",
    "with gr.Blocks(\n",
    "    title=\"Dr. GeoBot - Advanced Geoscience Chat Assistant\",\n",
    "    theme=gr.themes.Soft()\n",
    ") as demo:\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🌍 Dr. GeoBot - Your Advanced Geoscience Expert\n",
    "    \n",
    "    I'm an AI geoscience expert powered by modern LangChain. Ask me about:\n",
    "    \n",
    "    | **Geophysics** | **Petroleum Engineering** | **Well Logging** |\n",
    "    |---|---|---|\n",
    "    | Seismic interpretation | Reservoir characterization | Formation evaluation |\n",
    "    | Gravity & magnetics | Hydrocarbon systems | Petrophysics |\n",
    "    | Electromagnetics | Production optimization | Log analysis |\n",
    "    \n",
    "    💡 *I remember our conversation, so feel free to ask follow-up questions!*\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                value=[],\n",
    "                height=500,\n",
    "                show_label=False,\n",
    "                bubble_full_width=False\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    placeholder=\"Ask me about geoscience topics...\",\n",
    "                    show_label=False,\n",
    "                    scale=4,\n",
    "                    container=False\n",
    "                )\n",
    "                send_btn = gr.Button(\"Send 📤\", scale=1, variant=\"primary\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                clear_btn = gr.Button(\"🗑️ Clear Chat\", variant=\"secondary\")\n",
    "                \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### 💡 Example Questions\")\n",
    "            \n",
    "            example_questions = [\n",
    "                \"What is seismic inversion?\",\n",
    "                \"Explain porosity vs permeability\",\n",
    "                \"How do P-waves and S-waves differ?\",\n",
    "                \"What is reservoir characterization?\",\n",
    "                \"How does well logging work?\",\n",
    "                \"What are the challenges in unconventional reservoirs?\"\n",
    "            ]\n",
    "            \n",
    "            for question in example_questions:\n",
    "                example_btn = gr.Button(\n",
    "                    question,\n",
    "                    variant=\"secondary\",\n",
    "                    size=\"sm\"\n",
    "                )\n",
    "                example_btn.click(\n",
    "                    load_example,\n",
    "                    inputs=[gr.State(question)],\n",
    "                    outputs=msg\n",
    "                )\n",
    "    \n",
    "    # Event handlers\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    send_btn.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear_btn.click(clear_conversation, outputs=chatbot)\n",
    "\n",
    "# Launch the interface\n",
    "print(\"Launching modern Gradio interface...\")\n",
    "demo.launch(share=True, show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise: Advanced Geoscience Conversations\n",
    "\n",
    "Now let's test our modern chat agent with complex geoscience scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Advanced Geoscience Conversations with Galactica Model\n",
    "model_name = \"GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k\"\n",
    "\n",
    "print(f\"Loading Galactica model: {model_name}\")\n",
    "\n",
    "# Create tokenizer for Galactica\n",
    "\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "# Updated quantization config for the larger model\n",
    "\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "# Load the Galactica model\n",
    "\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "# Set pad token for Galactica\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "# Create pipeline for Galactica\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "# Create LangChain components for Galactica\n",
    "galactica_llm = \"\"\" YOUR CODE HERE \"\"\"\n",
    "galactica_chat_model = ChatHuggingFace(llm=galactica_llm)\n",
    "\n",
    "print(f\"Galactica model loaded successfully!\")\n",
    "print(f\"Model parameters: {galactica_model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Geoscience Chat Agent for Advanced Scientific Queries\n",
    "class AdvancedGeoscienceChatAgent(ModernGeoscienceChatAgent):\n",
    "    def __init__(self, chat_model):\n",
    "        super().__init__(chat_model)\n",
    "        \n",
    "        # Enhanced system prompt for scientific rigor with Galactica\n",
    "        self.system_prompt = \"\"\"\n",
    "        YOUR PROMPT HERE\n",
    "\"\"\"\n",
    "\n",
    "# Create the advanced agent with Galactica\n",
    "\"\"\" YOUR CODE HERE \"\"\"\n",
    "print(\"Advanced GeoscienceChatAgent with Galactica model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Scientific Query Categories\n",
    "advanced_scenarios = {\n",
    "    \"Quantitative Reservoir Analysis\": [\n",
    "        \"Calculate the hydrocarbon pore volume for a reservoir with 25% porosity, 65% water saturation, and net pay of 150 ft over 1000 acres.\",\n",
    "        \"What is the relationship between permeability and grain size in sandstone reservoirs? Provide the Kozeny-Carman equation.\",\n",
    "        \"How do you estimate original oil in place using volumetric methods? Include uncertainty analysis.\"\n",
    "    ],\n",
    "    \n",
    "    \"Advanced Seismic Interpretation\": [\n",
    "        \"Explain the physics behind AVO (Amplitude Versus Offset) analysis and the Zoeppritz equations.\",\n",
    "        \"How do you distinguish between structural and stratigraphic hydrocarbon traps using seismic attributes?\",\n",
    "        \"What are the key parameters in seismic resolution analysis? Provide the mathematical relationships.\"\n",
    "    ],\n",
    "    \n",
    "    \"Geomechanics & Drilling\": [\n",
    "        \"Calculate the minimum horizontal stress using the poroelastic theory. Include Biot's coefficient.\",\n",
    "        \"How do you predict wellbore stability using the Mohr-Coulomb failure criterion?\",\n",
    "        \"What factors control hydraulic fracture propagation in unconventional reservoirs?\"\n",
    "    ],\n",
    "    \n",
    "    \"Carbon Sequestration\": [\n",
    "        \"What are the key thermodynamic properties of CO2 at typical reservoir conditions (3000 ft depth, 120°F)?\",\n",
    "        \"How do you assess caprock integrity for CO2 storage? Include geochemical considerations.\",\n",
    "        \"Calculate the CO2 storage capacity using the methodology from the CO2 Storage Atlas.\"\n",
    "    ],\n",
    "    \n",
    "    \"Machine Learning in Geosciences\": [\n",
    "        \"How can neural networks be applied to seismic facies classification? What are the key preprocessing steps?\",\n",
    "        \"Explain the use of clustering algorithms for well log analysis and formation evaluation.\",\n",
    "        \"What machine learning approaches are most effective for reservoir property prediction from seismic data?\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_gradio_interface():\n",
    "    \"\"\"Create an advanced Gradio interface for scientific geoscience queries\"\"\"\n",
    "    \n",
    "    # Global session\n",
    "    global advanced_session\n",
    "    advanced_session = advanced_agent.create_new_session()\n",
    "    \n",
    "    def advanced_respond(message: str, history: List[Tuple[str, str]]) -> Tuple[str, List[Tuple[str, str]]]:\n",
    "        global advanced_session\n",
    "        \n",
    "        if not message.strip():\n",
    "            return \"\", history\n",
    "        \n",
    "        # Get response from advanced agent\n",
    "        bot_response = advanced_agent.chat(message, advanced_session)\n",
    "        history.append((message, bot_response))\n",
    "        return \"\", history\n",
    "    \n",
    "    def clear_advanced_conversation() -> List[Tuple[str, str]]:\n",
    "        global advanced_session\n",
    "        advanced_agent.clear_memory(advanced_session)\n",
    "        advanced_session = advanced_agent.create_new_session()\n",
    "        return []\n",
    "    \n",
    "    def load_scenario_questions(scenario_name: str) -> str:\n",
    "        \"\"\"Load all questions from a scenario\"\"\"\n",
    "        if scenario_name in advanced_scenarios:\n",
    "            questions = advanced_scenarios[scenario_name]\n",
    "            return \"\\n\\n\".join([f\"Q{i+1}: {q}\" for i, q in enumerate(questions)])\n",
    "        return \"\"\n",
    "    \n",
    "    # Create the interface\n",
    "    with gr.Blocks(\n",
    "        title=\"Dr. GeoBot-Advanced - Scientific Geoscience AI\",\n",
    "        theme=gr.themes.Base(),\n",
    "        css=\"\"\"\n",
    "        .gradio-container { background: linear-gradient(45deg, #1e3a8a, #1e40af) }\n",
    "        .chat-message { background: rgba(255,255,255,0.95); border-radius: 10px; }\n",
    "        \"\"\"\n",
    "    ) as advanced_demo:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # 🧬 Dr. GeoBot-Advanced - Scientific Geoscience AI\n",
    "        ### *Powered by Galactica-6.7B for Advanced Scientific Reasoning*\n",
    "        \n",
    "        | **🔬 Advanced Capabilities** | **📊 Quantitative Analysis** | **🎯 Research Applications** |\n",
    "        |---|---|---|\n",
    "        | Complex equation derivation | Statistical reservoir analysis | ML/AI in geosciences |\n",
    "        | Multi-physics modeling | Uncertainty quantification | Carbon sequestration |\n",
    "        | Advanced interpretation | Geomechanical calculations | Unconventional resources |\n",
    "        \n",
    "        💡 *Ask detailed scientific questions with quantitative requirements*\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    value=[],\n",
    "                    height=600,\n",
    "                    show_label=False,\n",
    "                    bubble_full_width=False,\n",
    "                    avatar_images=(\"🧑‍🔬\", \"🤖\")\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(\n",
    "                        placeholder=\"Ask advanced geoscience questions (include specific parameters, equations, calculations)...\",\n",
    "                        show_label=False,\n",
    "                        scale=5,\n",
    "                        container=False\n",
    "                    )\n",
    "                    send_btn = gr.Button(\"🚀 Analyze\", scale=1, variant=\"primary\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"🗑️ Clear Session\", variant=\"secondary\")\n",
    "                    export_btn = gr.Button(\"📋 Export Chat\", variant=\"secondary\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### 🔬 Advanced Query Categories\")\n",
    "                \n",
    "                scenario_dropdown = gr.Dropdown(\n",
    "                    choices=list(advanced_scenarios.keys()),\n",
    "                    label=\"Select Scientific Domain\",\n",
    "                    value=None\n",
    "                )\n",
    "                \n",
    "                scenario_text = gr.Textbox(\n",
    "                    label=\"Scenario Questions\",\n",
    "                    lines=8,\n",
    "                    placeholder=\"Select a domain to see advanced questions...\"\n",
    "                )\n",
    "                \n",
    "                load_scenario_btn = gr.Button(\"📖 Load Questions\", variant=\"secondary\")\n",
    "                \n",
    "                gr.Markdown(\"\"\"\n",
    "                ### 💡 Quick Examples\n",
    "                - *\"Calculate fracture pressure using Eaton's method\"*\n",
    "                - *\"Derive the Gardner equation for density prediction\"*\n",
    "                - *\"Explain Gassmann fluid substitution theory\"*\n",
    "                - *\"Model CO2 solubility in brine at reservoir conditions\"*\n",
    "                \"\"\")\n",
    "        \n",
    "        # Event handlers\n",
    "        msg.submit(advanced_respond, [msg, chatbot], [msg, chatbot])\n",
    "        send_btn.click(advanced_respond, [msg, chatbot], [msg, chatbot])\n",
    "        clear_btn.click(clear_advanced_conversation, outputs=chatbot)\n",
    "        \n",
    "        scenario_dropdown.change(\n",
    "            load_scenario_questions,\n",
    "            inputs=scenario_dropdown,\n",
    "            outputs=scenario_text\n",
    "        )\n",
    "        \n",
    "        load_scenario_btn.click(\n",
    "            lambda text: text,\n",
    "            inputs=scenario_text,\n",
    "            outputs=msg\n",
    "        )\n",
    "    \n",
    "    return advanced_demo\n",
    "\n",
    "# Create and launch the advanced interface\n",
    "print(\"Creating Gradio Interface with Galactica...\")\n",
    "advanced_demo = create_advanced_gradio_interface()\n",
    "advanced_demo.launch(share=True, show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we built a modern conversational AI agent using current LangChain best practices:\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Modern LangChain Architecture**:\n",
    "   - ✅ LCEL (LangChain Expression Language) for chain composition\n",
    "   - ✅ ChatModels and structured message handling\n",
    "   - ✅ RunnableWithMessageHistory for conversation management\n",
    "   - ✅ Proper session management and memory handling\n",
    "\n",
    "2. **Advanced Features**:\n",
    "   - ✅ Multi-session conversation support\n",
    "   - ✅ Structured prompt templates with MessagesPlaceholder\n",
    "   - ✅ Modern error handling and response parsing\n",
    "   - ✅ Session-based memory management\n",
    "\n",
    "3. **Geoscience Applications**:\n",
    "   - ✅ Domain-specific expert persona (Dr. GeoBot)\n",
    "   - ✅ Technical geoscience conversation scenarios\n",
    "   - ✅ Context-aware follow-up questions\n",
    "   - ✅ Multi-topic expertise coverage\n",
    "\n",
    "4. **Modern UI/UX**:\n",
    "   - ✅ Enhanced Gradio interface with themes\n",
    "   - ✅ Example question buttons for easy interaction\n",
    "   - ✅ Improved conversation display and management\n",
    "   - ✅ Session management and conversation clearing\n",
    "\n",
    "### Key Improvements Over Legacy LangChain:\n",
    "\n",
    "| **Legacy** | **Modern** |\n",
    "|---|---|\n",
    "| `LLMChain` | LCEL (`|` operator) |\n",
    "| `ConversationBufferMemory` | `RunnableWithMessageHistory` |\n",
    "| Manual prompt formatting | `ChatPromptTemplate` |\n",
    "| Basic error handling | Structured exception management |\n",
    "| Single conversation | Multi-session support |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Module 1.3**: Add RAG (Retrieval Augmented Generation) for factual accuracy\n",
    "- **Module 1.4**: Integrate external tools and function calling\n",
    "- **Session 2**: Fine-tune models on geoscience datasets\n",
    "- **Session 3**: Build specialized applications (seismic analysis, log interpretation)\n",
    "\n",
    "### Exercise Extensions:\n",
    "\n",
    "1. **Customize the Expert**: Modify the system prompt to create specialists (seismic interpreter, reservoir engineer, etc.)\n",
    "2. **Add Validation**: Implement response quality checking and topic relevance\n",
    "3. **Export Conversations**: Add functionality to save/load conversation sessions\n",
    "4. **Multi-Agent Setup**: Create multiple specialized agents for different domains\n",
    "5. **Integration**: Connect with geoscience APIs or databases for real-time data\n",
    "\n",
    "This modern implementation provides a solid foundation for building production-ready geoscience chat applications! 🌍"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
