{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4820df32",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/SPE_GeoHackathon_2025/blob/main/S1_M1_LLM_HF.ipynb)\n",
    "\n",
    "***\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by running each cell in order\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Make sure to run the environment setup cells first\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Wait for each installation to complete before proceeding\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if installations take a while - this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup [If running outside Colab]\n",
    "# !pip install transformers torch matplotlib plotly scikit-learn ipython\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face API token\n",
    "# Retrieving the token is required to get access to HF hub\n",
    "from google.colab import userdata\n",
    "hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7ecac",
   "metadata": {},
   "source": [
    "# Session 01 // Module 01: Large Language Models (LLMs) with HuggingFace\n",
    "\n",
    "In this module, we'll explore the fundamentals of Large Language Models (LLMs) using HuggingFace transformers. We'll cover tokens, embeddings, context windows, and hands-on text generation with a focus on geoscience applications.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what tokens, embeddings, and context windows are\n",
    "- Load and use a small HuggingFace model\n",
    "- Generate simple text completions\n",
    "- Apply LLMs to geoscience definition tasks\n",
    "\n",
    "## 1. Understanding Tokens\n",
    "\n",
    "**Tokens** are the basic units that language models work with. Text is broken down into tokens before being processed by the model. A token can be:\n",
    "- A whole word (e.g., \"seismic\")\n",
    "- Part of a word (e.g., \"seis\", \"mic\")\n",
    "- Punctuation marks\n",
    "- Special symbols\n",
    "\n",
    "Let's see how tokenization works with a geoscience example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use utils library\n",
    "from IPython.display import HTML, display\n",
    "def bert_tokenize_and_color(text, tokenizer ):\n",
    "    colored_text = \"\"\n",
    "    colors = ['#FF5733', '#33FF57', '#3357FF', '#FFD700', '#00CED1', '#FF00FF', '#FFFF00',\n",
    "              '#FF0000', '#00FF00', '#0000FF', '#00FFFF', '#FF1493', '#8A2BE2',\n",
    "              '#FF8C00', '#228B22', '#DC143C', '#32CD32', '#1E90FF', '#FFD700', '#FF69B4']\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    colored_html = \"\"\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        color = colors[i % len(colors)]\n",
    "        # Replace special characters for display\n",
    "        display_token = token.replace('Ġ', '▁')  # GPT-2 uses Ġ for spaces\n",
    "        colored_html += f'<span style=\"background-color:{color}; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">{display_token}</span>'\n",
    "    \n",
    "    print(f\"Original text: {text}\")\n",
    "    print(f\"Number of tokens: {len(tokens)}\")\n",
    "    display(HTML(colored_html))\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d663928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Geoscience text examples\n",
    "texts = [\n",
    "    \"Seismic inversion is a geophysical technique.\",\n",
    "    \"Hydrocarbon exploration uses seismic surveys.\",\n",
    "    \"Reservoir characterization involves petrophysical analysis.\",\n",
    "    \"What is the porosity and permeability of this formation?\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    bert_tokenize_and_color(text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample vocabulary, special tokens, and token mapping\n",
    "\n",
    "# Sample vocab (first 20 keys)\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Sample vocabulary (first 20):\", list(vocab.keys())[:20])\n",
    "\n",
    "# Special tokens\n",
    "print(\"\\nSpecial tokens:\", tokenizer.special_tokens_map)\n",
    "\n",
    "# Mapping for the first line of the poem\n",
    "sample_text = text[0]\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Full encoding for the first line\n",
    "encoded = tokenizer(sample_text, return_tensors='pt')\n",
    "print(f\"\\nFull encoding (input_ids): {encoded['input_ids']}\")\n",
    "print(f\"Attention mask: {encoded['attention_mask']}\")\n",
    "\n",
    "decoded = tokenizer.decode(token_ids)\n",
    "print(f\"Decoded tokens: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ecf0c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- You can use `AutoTokenizer` for automatic model selection.\n",
    "- To perform tokenization, you can use the `tokenizer` object created from the `BertTokenizer` class or the `AutoTokenizer` class.\n",
    "\n",
    "## 2. Understanding Embeddings\n",
    "\n",
    "**Embeddings** are numerical representations of tokens in a high-dimensional space. Each token is converted to a vector of numbers that captures its meaning and relationships to other tokens.\n",
    "\n",
    "Key properties of embeddings:\n",
    "- Similar words have similar embeddings\n",
    "- Embeddings capture semantic relationships\n",
    "- Typical dimensions: 512, 768, 1024, or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load a small model for embeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained(model_name)\n",
    "model_embed = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings(texts, tokenizer, model):\n",
    "    \"\"\"Get sentence embeddings\"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use CLS token embedding (first token) for sentence representation\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Get embeddings for geoscience terms\n",
    "geoscience_terms = [\n",
    "    \"seismic inversion\",\n",
    "    \"reservoir characterization\", \n",
    "    \"hydrocarbon exploration\",\n",
    "    \"petrophysical analysis\",\n",
    "    \"porosity measurement\",\n",
    "    \"permeability analysis\"\n",
    "]\n",
    "\n",
    "embeddings = get_embeddings(geoscience_terms, tokenizer_embed, model_embed)\n",
    "\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Each term is represented by {embeddings.shape[1]} numbers\")\n",
    "print(f\"\\nFirst 10 embedding values for '{geoscience_terms[0]}':\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model + tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Comprehensive geophysics and petroleum engineering texts\n",
    "geophysics_texts = [\n",
    "    # Seismic Methods\n",
    "    \"Seismic inversion transforms seismic reflection data into quantitative subsurface rock properties.\",\n",
    "    \"P-wave velocity depends on rock density and bulk modulus in elastic media.\",\n",
    "    \"S-wave velocity is controlled by shear modulus and density of the formation.\",\n",
    "    \"Seismic amplitude variation with offset reveals fluid content and lithology changes.\",\n",
    "    \"Pre-stack seismic inversion simultaneously estimates multiple elastic parameters from angle stacks.\",\n",
    "    \"Post-stack seismic inversion derives acoustic impedance from normal incidence reflectivity.\",\n",
    "    \"Seismic interpretation identifies structural features like faults, folds, and stratigraphic boundaries.\",\n",
    "    \"Time-lapse seismic monitoring tracks reservoir changes during production and injection.\",\n",
    "    \n",
    "    # Reservoir Properties\n",
    "    \"Porosity measures the void space available for fluid storage in reservoir rocks.\",\n",
    "    \"Permeability quantifies the ability of fluids to flow through porous rock matrices.\",\n",
    "    \"Water saturation represents the fraction of pore space occupied by formation water.\",\n",
    "    \"Net-to-gross ratio indicates the proportion of reservoir quality rock in a formation.\",\n",
    "    \"Reservoir pressure drives hydrocarbon flow from formation to wellbore during production.\",\n",
    "    \"Capillary pressure controls fluid distribution at pore scale in reservoir rocks.\",\n",
    "    \"Relative permeability curves describe multiphase flow behavior in porous media.\",\n",
    "    \"Formation volume factor accounts for fluid expansion from reservoir to surface conditions.\",\n",
    "    \n",
    "    # Well Logging\n",
    "    \"Gamma ray logs measure natural radioactivity to identify shale and clay content.\",\n",
    "    \"Resistivity logs detect hydrocarbon presence by measuring electrical resistance of formations.\",\n",
    "    \"Neutron logs respond to hydrogen content, indicating porosity and fluid types.\",\n",
    "    \"Density logs measure bulk density to calculate porosity and identify lithology.\",\n",
    "    \"Photoelectric factor from density logs helps distinguish different rock types and minerals.\",\n",
    "    \"Spontaneous potential logs indicate permeable zones and formation water resistivity.\",\n",
    "    \"Caliper logs measure borehole diameter to identify washouts and tight spots.\",\n",
    "    \"Nuclear magnetic resonance logs provide pore size distribution and permeability estimates.\",\n",
    "    \n",
    "    # Drilling and Completion\n",
    "    \"Drilling mud maintains wellbore stability and carries cuttings to surface.\",\n",
    "    \"Casing design protects formations and enables safe drilling to target depths.\",\n",
    "    \"Hydraulic fracturing creates artificial fractures to enhance reservoir permeability.\",\n",
    "    \"Horizontal drilling maximizes contact with thin reservoir layers.\",\n",
    "    \"Perforation creates communication pathways between wellbore and reservoir.\",\n",
    "    \"Sand control prevents formation sand production that could damage equipment.\",\n",
    "    \"Acidizing dissolves formation damage and enhances near-wellbore permeability.\",\n",
    "    \"Wellbore trajectory optimization maximizes reservoir contact while avoiding hazards.\",\n",
    "    \n",
    "    # Production Engineering\n",
    "    \"Artificial lift systems maintain production when reservoir pressure declines.\",\n",
    "    \"Nodal analysis optimizes production system performance from reservoir to separator.\",\n",
    "    \"Decline curve analysis predicts future production rates and ultimate recovery.\",\n",
    "    \"Enhanced oil recovery techniques mobilize residual oil after primary depletion.\",\n",
    "    \"Water flooding maintains reservoir pressure and sweeps oil toward producers.\",\n",
    "    \"Gas injection improves oil recovery through miscible or immiscible displacement.\",\n",
    "    \"Thermal recovery methods reduce oil viscosity in heavy oil reservoirs.\",\n",
    "    \"Production optimization balances rate, pressure, and equipment constraints.\",\n",
    "    \n",
    "    # Geology and Geochemistry\n",
    "    \"Source rock maturation generates hydrocarbons through thermal decomposition of organic matter.\",\n",
    "    \"Migration pathways allow hydrocarbons to move from source to reservoir rocks.\",\n",
    "    \"Structural traps accumulate hydrocarbons through folding and faulting processes.\",\n",
    "    \"Stratigraphic traps form through depositional and diagenetic rock property changes.\",\n",
    "    \"Seal integrity prevents hydrocarbon leakage from reservoir to surface.\",\n",
    "    \"Basin modeling predicts hydrocarbon generation, migration, and accumulation timing.\",\n",
    "    \"Sequence stratigraphy correlates rock units across regional geological frameworks.\",\n",
    "    \"Diagenesis modifies reservoir quality through cementation and dissolution processes.\",\n",
    "    \n",
    "    # Advanced Technologies\n",
    "    \"Machine learning algorithms identify patterns in seismic and well log data.\",\n",
    "    \"Digital twins create virtual reservoir models for production optimization.\",\n",
    "    \"Microseismic monitoring tracks fracture growth during stimulation operations.\",\n",
    "    \"Fiber optic sensing provides distributed measurements along wellbore length.\",\n",
    "    \"Cloud computing enables large-scale reservoir simulation and data analytics.\",\n",
    "    \"Automated drilling systems improve efficiency and reduce human error.\",\n",
    "    \"Real-time optimization adjusts operations based on continuous data streams.\",\n",
    "    \"Carbon capture and storage requires geological characterization for safe sequestration.\"\n",
    "]\n",
    "\n",
    "print(f\"Total number of geophysics texts: {len(geophysics_texts)}\")\n",
    "print(\"Sample texts:\")\n",
    "for i, text in enumerate(geophysics_texts[:5]):\n",
    "    print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b87e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all geophysics sentences\n",
    "inputs = tokenizer(geophysics_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs).last_hidden_state[:,0,:]  # CLS token\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Each sentence is represented by {embeddings.shape[1]} dimensional vector\")\n",
    "\n",
    "# Reduce dimensions to 3D with t-SNE\n",
    "# Adjust perplexity based on dataset size (should be less than n_samples)\n",
    "perplexity = min(30, len(geophysics_texts) - 1)\n",
    "tsne = TSNE(n_components=3, perplexity=perplexity, random_state=42, max_iter=1000)\n",
    "embeddings_3d = tsne.fit_transform(embeddings.numpy())\n",
    "\n",
    "print(f\"3D embeddings shape: {embeddings_3d.shape}\")\n",
    "print(f\"Using perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaad5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Create category labels for color coding\n",
    "categories = []\n",
    "category_names = [\n",
    "    \"Seismic Methods\", \"Seismic Methods\", \"Seismic Methods\", \"Seismic Methods\", \n",
    "    \"Seismic Methods\", \"Seismic Methods\", \"Seismic Methods\", \"Seismic Methods\",\n",
    "    \"Reservoir Properties\", \"Reservoir Properties\", \"Reservoir Properties\", \"Reservoir Properties\",\n",
    "    \"Reservoir Properties\", \"Reservoir Properties\", \"Reservoir Properties\", \"Reservoir Properties\",\n",
    "    \"Well Logging\", \"Well Logging\", \"Well Logging\", \"Well Logging\",\n",
    "    \"Well Logging\", \"Well Logging\", \"Well Logging\", \"Well Logging\",\n",
    "    \"Drilling & Completion\", \"Drilling & Completion\", \"Drilling & Completion\", \"Drilling & Completion\",\n",
    "    \"Drilling & Completion\", \"Drilling & Completion\", \"Drilling & Completion\", \"Drilling & Completion\",\n",
    "    \"Production Engineering\", \"Production Engineering\", \"Production Engineering\", \"Production Engineering\",\n",
    "    \"Production Engineering\", \"Production Engineering\", \"Production Engineering\", \"Production Engineering\",\n",
    "    \"Geology & Geochemistry\", \"Geology & Geochemistry\", \"Geology & Geochemistry\", \"Geology & Geochemistry\",\n",
    "    \"Geology & Geochemistry\", \"Geology & Geochemistry\", \"Geology & Geochemistry\", \"Geology & Geochemistry\",\n",
    "    \"Advanced Technologies\", \"Advanced Technologies\", \"Advanced Technologies\", \"Advanced Technologies\",\n",
    "    \"Advanced Technologies\", \"Advanced Technologies\", \"Advanced Technologies\", \"Advanced Technologies\"\n",
    "]\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    x=embeddings_3d[:,0],\n",
    "    y=embeddings_3d[:,1],\n",
    "    z=embeddings_3d[:,2],\n",
    "    hover_name=geophysics_texts,\n",
    "    color=category_names,\n",
    "    title=\"Interactive 3D Geophysics Text Embeddings\",\n",
    "    labels={'x':'Dimension 1', 'y':'Dimension 2', 'z':'Dimension 3'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.8))\n",
    "fig.update_layout(\n",
    "    font_family='Arial',\n",
    "    width=1000, \n",
    "    height=800,\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Semantic Dimension 1\",\n",
    "        yaxis_title=\"Semantic Dimension 2\",\n",
    "        zaxis_title=\"Semantic Dimension 3\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b402491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze semantic similarities within categories\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings.numpy())\n",
    "\n",
    "# Find most similar sentence pairs\n",
    "similarity_pairs = []\n",
    "for i in range(len(geophysics_texts)):\n",
    "    for j in range(i+1, len(geophysics_texts)):\n",
    "        similarity_pairs.append({\n",
    "            'text1': geophysics_texts[i][:50] + '...',\n",
    "            'text2': geophysics_texts[j][:50] + '...',\n",
    "            'category1': category_names[i],\n",
    "            'category2': category_names[j],\n",
    "            'similarity': similarity_matrix[i, j],\n",
    "            'same_category': category_names[i] == category_names[j]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and sort by similarity\n",
    "df_similarities = pd.DataFrame(similarity_pairs)\n",
    "df_top_similar = df_similarities.nlargest(10, 'similarity')\n",
    "\n",
    "print(\"Top 10 Most Similar Sentence Pairs:\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in df_top_similar.iterrows():\n",
    "    same_cat = \"✓\" if row['same_category'] else \"✗\"\n",
    "    print(f\"Similarity: {row['similarity']:.3f} | Same Category: {same_cat}\")\n",
    "    print(f\"1. [{row['category1']}] {row['text1']}\")\n",
    "    print(f\"2. [{row['category2']}] {row['text2']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate average similarity within vs between categories\n",
    "within_category_sim = df_similarities[df_similarities['same_category']]['similarity'].mean()\n",
    "between_category_sim = df_similarities[~df_similarities['same_category']]['similarity'].mean()\n",
    "\n",
    "print(f\"\\nAverage similarity within same category: {within_category_sim:.3f}\")\n",
    "print(f\"Average similarity between different categories: {between_category_sim:.3f}\")\n",
    "print(f\"Difference: {within_category_sim - between_category_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56368ac5",
   "metadata": {},
   "source": [
    "## 3. Understanding Context Windows\n",
    "\n",
    "**Context window** refers to the maximum number of tokens a model can process at once. This is a crucial limitation that affects:\n",
    "- How much text the model can \"remember\"\n",
    "- The maximum input size for generation tasks\n",
    "- Computational requirements\n",
    "\n",
    "Common context window sizes:\n",
    "- GPT-2: 1,024 tokens\n",
    "- GPT-3: 4,096 tokens  \n",
    "- GPT-4: 8,192 - 32,768 tokens\n",
    "- Claude: 100,000+ tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate context window limitations\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load GPT-2 model\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set pad token\n",
    "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
    "\n",
    "print(f\"GPT-2 maximum position embeddings: {model_gpt2.config.n_positions}\")\n",
    "print(f\"This means the context window is {model_gpt2.config.n_positions} tokens\")\n",
    "\n",
    "# Create a long geoscience text to test context limits\n",
    "long_text = \"\"\"\n",
    "Seismic inversion is a geophysical technique used to derive subsurface properties from seismic data. \n",
    "The process involves converting seismic reflection data into quantitative rock and fluid properties such as \n",
    "acoustic impedance, porosity, and lithology. This technique is fundamental in hydrocarbon exploration \n",
    "and reservoir characterization. The inversion process typically starts with seismic data acquisition, \n",
    "followed by data processing, and finally the inversion itself. There are several types of seismic inversion \n",
    "including post-stack inversion, pre-stack inversion, and simultaneous inversion. Post-stack inversion \n",
    "works with stacked seismic data to derive acoustic impedance. Pre-stack inversion uses angle-dependent \n",
    "reflectivity information to derive multiple elastic properties. Simultaneous inversion integrates seismic \n",
    "and well log data to provide more accurate and detailed subsurface models.\n",
    "\"\"\" * 10  # Repeat to make it longer\n",
    "\n",
    "# Tokenize the long text\n",
    "tokens = tokenizer_gpt2.tokenize(long_text)\n",
    "print(f\"\\nLong text has {len(tokens)} tokens\")\n",
    "print(f\"Exceeds context window: {len(tokens) > model_gpt2.config.n_positions}\")\n",
    "\n",
    "# Show what happens when we truncate\n",
    "max_length = model_gpt2.config.n_positions - 50  # Leave room for generation\n",
    "truncated_tokens = tokens[:max_length]\n",
    "print(f\"Truncated to {len(truncated_tokens)} tokens for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e6952",
   "metadata": {},
   "source": [
    "## 4. Loading a Small HuggingFace Model\n",
    "\n",
    "Let's load and explore a small language model suitable for text generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2976d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load a small, efficient model for text generation\n",
    "model_name = \"distilgpt2\"  # Smaller, faster version of GPT-2\n",
    "tokenizer_gen = AutoTokenizer.from_pretrained(model_name)\n",
    "model_gen = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set pad token\n",
    "if tokenizer_gen.pad_token is None:\n",
    "    tokenizer_gen.pad_token = tokenizer_gen.eos_token\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Vocabulary size: {tokenizer_gen.vocab_size:,}\")\n",
    "print(f\"Model parameters: {model_gen.num_parameters():,}\")\n",
    "print(f\"Context window: {model_gen.config.n_positions} tokens\")\n",
    "print(f\"Embedding dimension: {model_gen.config.n_embd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664990a",
   "metadata": {},
   "source": [
    "## 5. Generate Simple Text Completions\n",
    "\n",
    "Now let's use our model to generate text completions with various prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45267a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, tokenizer, model, max_length=100, temperature=0.7, num_return_sequences=1):\n",
    "    \"\"\"Generate text completion given a prompt\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2  # Avoid repetition\n",
    "        )\n",
    "    \n",
    "    generated_texts = []\n",
    "    for output in outputs:\n",
    "        generated_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        generated_texts.append(generated_text)\n",
    "    \n",
    "    return generated_texts\n",
    "\n",
    "# Test with simple prompts\n",
    "simple_prompts = [\n",
    "    \"The geology of this region\",\n",
    "    \"Oil and gas exploration requires\",\n",
    "    \"Seismic waves travel through\"\n",
    "]\n",
    "\n",
    "print(\"=== Simple Text Completions ===\")\n",
    "for prompt in simple_prompts:\n",
    "    generated = generate_text(prompt, tokenizer_gen, model_gen, max_length=60)\n",
    "    print(f\"\\nPrompt: '{prompt}'\")\n",
    "    print(f\"Completion: '{generated[0]}'\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different generation parameters\n",
    "prompt = \"Reservoir characterization involves\"\n",
    "\n",
    "print(\"=== Effect of Different Parameters ===\")\n",
    "print(f\"Prompt: '{prompt}'\\n\")\n",
    "\n",
    "# Low temperature (more deterministic)\n",
    "low_temp = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=0.3)\n",
    "print(f\"Low temperature (0.3): {low_temp[0]}\")\n",
    "\n",
    "# High temperature (more creative)\n",
    "high_temp = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=1.2)\n",
    "print(f\"High temperature (1.2): {high_temp[0]}\")\n",
    "\n",
    "# Multiple generations\n",
    "multiple = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=0.8, num_return_sequences=3)\n",
    "print(\"\\nMultiple generations:\")\n",
    "for i, gen in enumerate(multiple, 1):\n",
    "    print(f\"{i}. {gen}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
