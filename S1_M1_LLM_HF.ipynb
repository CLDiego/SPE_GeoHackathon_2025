{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4820df32",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/SPE_GeoHackathon_2025/blob/main/S1_M1_LLM_HF.ipynb)\n",
    "\n",
    "***\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by running each cell in order\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Make sure to run the environment setup cells first\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Wait for each installation to complete before proceeding\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if installations take a while - this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup [If running outside Colab]\n",
    "# !pip install transformers torch matplotlib plotly scikit-learn ipython\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face API token\n",
    "# Retrieving the token is required to get access to HF hub\n",
    "from google.colab import userdata\n",
    "hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7ecac",
   "metadata": {},
   "source": [
    "# Session 01 // Module 01: Large Language Models (LLMs) with HuggingFace\n",
    "\n",
    "In this module, we'll explore the fundamentals of Large Language Models (LLMs) using HuggingFace transformers. We'll cover tokens, embeddings, context windows, and hands-on text generation with a focus on geoscience applications.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what tokens, embeddings, and context windows are\n",
    "- Load and use a small HuggingFace model\n",
    "- Generate simple text completions\n",
    "- Apply LLMs to geoscience definition tasks\n",
    "\n",
    "## 1. Understanding Tokens\n",
    "\n",
    "**Tokens** are the basic units that language models work with. Text is broken down into tokens before being processed by the model. A token can be:\n",
    "- A whole word (e.g., \"seismic\")\n",
    "- Part of a word (e.g., \"seis\", \"mic\")\n",
    "- Punctuation marks\n",
    "- Special symbols\n",
    "\n",
    "Let's see how tokenization works with a geoscience example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use utils library\n",
    "def bert_tokenize_and_color(text, tokenizer ):\n",
    "    colored_text = \"\"\n",
    "    colors = ['#FF5733', '#33FF57', '#3357FF', '#FFD700', '#00CED1', '#FF00FF', '#FFFF00',\n",
    "              '#FF0000', '#00FF00', '#0000FF', '#00FFFF', '#FF1493', '#8A2BE2',\n",
    "              '#FF8C00', '#228B22', '#DC143C', '#32CD32', '#1E90FF', '#FFD700', '#FF69B4']\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    colored_html = \"\"\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        color = colors[i % len(colors)]\n",
    "        # Replace special characters for display\n",
    "        display_token = token.replace('Ġ', '▁')  # GPT-2 uses Ġ for spaces\n",
    "        colored_html += f'<span style=\"background-color:{color}; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">{display_token}</span>'\n",
    "    \n",
    "    print(f\"Original text: {text}\")\n",
    "    print(f\"Number of tokens: {len(tokens)}\")\n",
    "    display(HTML(colored_html))\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d663928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Geoscience text examples\n",
    "text = [\n",
    "    \"Seismic inversion is a geophysical technique.\",\n",
    "    \"Hydrocarbon exploration uses seismic surveys.\",\n",
    "    \"Reservoir characterization involves petrophysical analysis.\",\n",
    "    \"What is the porosity and permeability of this formation?\"\n",
    "]\n",
    "\n",
    "bert_tokenize_and_color(text, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
