{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4820df32",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/SPE_GeoHackathon_2025/blob/main/S1_M1_LLM_HF.ipynb)\n",
    "\n",
    "***\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by running each cell in order\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Make sure to run the environment setup cells first\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Wait for each installation to complete before proceeding\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if installations take a while - this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup [If running outside Colab]\n",
    "# !pip install transformers torch matplotlib plotly scikit-learn ipython\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face API token\n",
    "# Retrieving the token is required to get access to HF hub\n",
    "from google.colab import userdata\n",
    "hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7ecac",
   "metadata": {},
   "source": [
    "# Session 01 // Module 01: Large Language Models (LLMs) with HuggingFace\n",
    "\n",
    "In this module, we'll explore the fundamentals of Large Language Models (LLMs) using HuggingFace transformers. We'll cover tokens, embeddings, context windows, and hands-on text generation with a focus on geoscience applications.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what tokens, embeddings, and context windows are\n",
    "- Load and use a small HuggingFace model\n",
    "- Generate simple text completions\n",
    "- Apply LLMs to geoscience definition tasks\n",
    "\n",
    "## 1. Understanding Tokens\n",
    "\n",
    "**Tokens** are the basic units that language models work with. Text is broken down into tokens before being processed by the model. A token can be:\n",
    "- A whole word (e.g., \"seismic\")\n",
    "- Part of a word (e.g., \"seis\", \"mic\")\n",
    "- Punctuation marks\n",
    "- Special symbols\n",
    "\n",
    "Let's see how tokenization works with a geoscience example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use utils library\n",
    "from IPython.display import HTML, display\n",
    "def bert_tokenize_and_color(text, tokenizer ):\n",
    "    colored_text = \"\"\n",
    "    colors = ['#FF5733', '#33FF57', '#3357FF', '#FFD700', '#00CED1', '#FF00FF', '#FFFF00',\n",
    "              '#FF0000', '#00FF00', '#0000FF', '#00FFFF', '#FF1493', '#8A2BE2',\n",
    "              '#FF8C00', '#228B22', '#DC143C', '#32CD32', '#1E90FF', '#FFD700', '#FF69B4']\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    colored_html = \"\"\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        color = colors[i % len(colors)]\n",
    "        # Replace special characters for display\n",
    "        display_token = token.replace('Ġ', '▁')  # GPT-2 uses Ġ for spaces\n",
    "        colored_html += f'<span style=\"background-color:{color}; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">{display_token}</span>'\n",
    "    \n",
    "    print(f\"Original text: {text}\")\n",
    "    print(f\"Number of tokens: {len(tokens)}\")\n",
    "    display(HTML(colored_html))\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d663928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Geoscience text examples\n",
    "texts = [\n",
    "    \"Seismic inversion is a geophysical technique.\",\n",
    "    \"Hydrocarbon exploration uses seismic surveys.\",\n",
    "    \"Reservoir characterization involves petrophysical analysis.\",\n",
    "    \"What is the porosity and permeability of this formation?\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    bert_tokenize_and_color(text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample vocabulary, special tokens, and token mapping\n",
    "\n",
    "# Sample vocab (first 20 keys)\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Sample vocabulary (first 20):\", list(vocab.keys())[:20])\n",
    "\n",
    "# Special tokens\n",
    "print(\"\\nSpecial tokens:\", tokenizer.special_tokens_map)\n",
    "\n",
    "# Mapping for the first line of the poem\n",
    "sample_text = text[0]\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Full encoding for the first line\n",
    "encoded = tokenizer(sample_text, return_tensors='pt')\n",
    "print(f\"\\nFull encoding (input_ids): {encoded['input_ids']}\")\n",
    "print(f\"Attention mask: {encoded['attention_mask']}\")\n",
    "\n",
    "decoded = tokenizer.decode(token_ids)\n",
    "print(f\"Decoded tokens: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ecf0c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- You can use `AutoTokenizer` for automatic model selection.\n",
    "- To perform tokenization, you can use the `tokenizer` object created from the `BertTokenizer` class or the `AutoTokenizer` class.\n",
    "\n",
    "## 2. Understanding Embeddings\n",
    "\n",
    "**Embeddings** are numerical representations of tokens in a high-dimensional space. Each token is converted to a vector of numbers that captures its meaning and relationships to other tokens.\n",
    "\n",
    "Key properties of embeddings:\n",
    "- Similar words have similar embeddings\n",
    "- Embeddings capture semantic relationships\n",
    "- Typical dimensions: 512, 768, 1024, or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load a small model for embeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained(model_name)\n",
    "model_embed = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings(texts, tokenizer, model):\n",
    "    \"\"\"Get sentence embeddings\"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use CLS token embedding (first token) for sentence representation\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Get embeddings for geoscience terms\n",
    "geoscience_terms = [\n",
    "    \"seismic inversion\",\n",
    "    \"reservoir characterization\", \n",
    "    \"hydrocarbon exploration\",\n",
    "    \"petrophysical analysis\",\n",
    "    \"porosity measurement\",\n",
    "    \"permeability analysis\"\n",
    "]\n",
    "\n",
    "embeddings = get_embeddings(geoscience_terms, tokenizer_embed, model_embed)\n",
    "\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Each term is represented by {embeddings.shape[1]} numbers\")\n",
    "print(f\"\\nFirst 10 embedding values for '{geoscience_terms[0]}':\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode sentences\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    embeddings = model_embed(**inputs).last_hidden_state[:,0,:]  # CLS token\n",
    "\n",
    "# Reduce dimensions to 3D with t-SNE\n",
    "tsne = TSNE(n_components=3, perplexity=5, random_state=42)\n",
    "embeddings_3d = tsne.fit_transform(embeddings.numpy())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
