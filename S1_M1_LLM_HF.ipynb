{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4820df32",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/SPE_GeoHackathon_2025/blob/main/S1_M1_LLM_HF.ipynb)\n",
    "\n",
    "***\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by running each cell in order\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Make sure to run the environment setup cells first\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Wait for each installation to complete before proceeding\n",
    "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if installations take a while - this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ef834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download utils from GitHub\n",
    "!wget -q --show-progress https://raw.githubusercontent.com/CLDiego/SPE_GeoHackathon_2025/dev/spe_utils.txt -O spe_utils.txt\n",
    "!wget -q --show-progress -x -nH --cut-dirs=3 -i spe_utils.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379fa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup [If running outside Colab]\n",
    "# !pip install transformers torch matplotlib plotly scikit-learn ipython\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aca3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face API token\n",
    "# Retrieving the token is required to get access to HF hub\n",
    "# from google.colab import userdata\n",
    "# hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e58f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty of Science and Engineering ðŸ”¬\n",
      "\u001b[95mThe University of Manchester \u001b[0m\n",
      "Invoking SPE GeoHackathon 2025 utils version: \u001b[92m0.0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import spe_utilts.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c15f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spe_utilts.data import (\n",
    "    GEOSCIENCE_TERMS,\n",
    "    TOKENIZATION_EXAMPLES,\n",
    "    SIMPLE_PROMPTS,\n",
    "    GEOPHYSICS_TEXTS,\n",
    "    GEOPHYSICS_CATEGORIES,\n",
    "    get_texts_by_category,\n",
    "    get_available_categories,\n",
    "    get_random_texts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7ecac",
   "metadata": {},
   "source": [
    "# Session 01 // Module 01: Large Language Models (LLMs) with HuggingFace\n",
    "\n",
    "In this module, we'll explore the fundamentals of Large Language Models (LLMs) using HuggingFace transformers. We'll cover tokens, embeddings, context windows, and hands-on text generation with a focus on geoscience applications.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what tokens, embeddings, and context windows are\n",
    "- Load and use a small HuggingFace model\n",
    "- Generate simple text completions\n",
    "- Apply LLMs to geoscience definition tasks\n",
    "\n",
    "## 1. Understanding Tokens\n",
    "\n",
    "**Tokens** are the basic units that language models work with. Text is broken down into tokens before being processed by the model. A token can be:\n",
    "- A whole word (e.g., \"seismic\")\n",
    "- Part of a word (e.g., \"seis\", \"mic\")\n",
    "- Punctuation marks\n",
    "- Special symbols\n",
    "\n",
    "Let's see how tokenization works with a geoscience example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d663928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Seismic inversion is a geophysical technique.\n",
      "Number of tokens: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#FF5733; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">seismic</span><span style=\"background-color:#33FF57; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">inversion</span><span style=\"background-color:#3357FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">is</span><span style=\"background-color:#FFD700; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">a</span><span style=\"background-color:#00CED1; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">geo</span><span style=\"background-color:#FF00FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##physical</span><span style=\"background-color:#FFFF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">technique</span><span style=\"background-color:#FF0000; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['seismic', 'inversion', 'is', 'a', 'geo', '##physical', 'technique', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "Original text: Hydrocarbon exploration uses seismic surveys.\n",
      "Number of tokens: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#FF5733; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">hydro</span><span style=\"background-color:#33FF57; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##carbon</span><span style=\"background-color:#3357FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">exploration</span><span style=\"background-color:#FFD700; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">uses</span><span style=\"background-color:#00CED1; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">seismic</span><span style=\"background-color:#FF00FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">surveys</span><span style=\"background-color:#FFFF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['hydro', '##carbon', 'exploration', 'uses', 'seismic', 'surveys', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "Original text: Reservoir characterization involves petrophysical analysis.\n",
      "Number of tokens: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#FF5733; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">reservoir</span><span style=\"background-color:#33FF57; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">characterization</span><span style=\"background-color:#3357FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">involves</span><span style=\"background-color:#FFD700; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">pet</span><span style=\"background-color:#00CED1; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##rop</span><span style=\"background-color:#FF00FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##hy</span><span style=\"background-color:#FFFF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##sic</span><span style=\"background-color:#FF0000; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##al</span><span style=\"background-color:#00FF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">analysis</span><span style=\"background-color:#0000FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['reservoir', 'characterization', 'involves', 'pet', '##rop', '##hy', '##sic', '##al', 'analysis', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "Original text: What is the porosity and permeability of this formation?\n",
      "Number of tokens: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#FF5733; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">what</span><span style=\"background-color:#33FF57; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">is</span><span style=\"background-color:#3357FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">the</span><span style=\"background-color:#FFD700; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">por</span><span style=\"background-color:#00CED1; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##osity</span><span style=\"background-color:#FF00FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">and</span><span style=\"background-color:#FFFF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">per</span><span style=\"background-color:#FF0000; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##me</span><span style=\"background-color:#00FF00; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">##ability</span><span style=\"background-color:#0000FF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">of</span><span style=\"background-color:#00FFFF; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">this</span><span style=\"background-color:#FF1493; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">formation</span><span style=\"background-color:#8A2BE2; color: white; padding: 2px 4px; margin: 1px; border-radius: 3px;\">?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['what', 'is', 'the', 'por', '##osity', 'and', 'per', '##me', '##ability', 'of', 'this', 'formation', '?']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from spe_utilts.visualisation import bert_tokenize_and_color\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "for text in TOKENIZATION_EXAMPLES:\n",
    "    bert_tokenize_and_color(text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1032a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample vocabulary (first 20): ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]']\n",
      "\n",
      "Special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n",
      "\n",
      "Sample text: Seismic inversion is a geophysical technique.\n",
      "Tokens: ['seismic', 'inversion', 'is', 'a', 'geo', '##physical', 'technique', '.']\n",
      "Token IDs: [22630, 28527, 2003, 1037, 20248, 23302, 6028, 1012]\n",
      "\n",
      "Full encoding (input_ids): tensor([[  101, 22630, 28527,  2003,  1037, 20248, 23302,  6028,  1012,   102]])\n",
      "Attention mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Decoded tokens: seismic inversion is a geophysical technique.\n"
     ]
    }
   ],
   "source": [
    "# Display sample vocabulary, special tokens, and token mapping\n",
    "\n",
    "# Sample vocab (first 20 keys)\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Sample vocabulary (first 20):\", list(vocab.keys())[:20])\n",
    "\n",
    "# Special tokens\n",
    "print(\"\\nSpecial tokens:\", tokenizer.special_tokens_map)\n",
    "\n",
    "# Mapping for the first tokenization example\n",
    "sample_text = TOKENIZATION_EXAMPLES[0]  \n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Full encoding for the first example\n",
    "encoded = tokenizer(sample_text, return_tensors='pt')\n",
    "print(f\"\\nFull encoding (input_ids): {encoded['input_ids']}\")\n",
    "print(f\"Attention mask: {encoded['attention_mask']}\")\n",
    "\n",
    "decoded = tokenizer.decode(token_ids)\n",
    "print(f\"Decoded tokens: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ecf0c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- You can use `AutoTokenizer` for automatic model selection.\n",
    "- To perform tokenization, you can use the `tokenizer` object created from the `BertTokenizer` class or the `AutoTokenizer` class.\n",
    "\n",
    "## 2. Understanding Embeddings\n",
    "\n",
    "**Embeddings** are numerical representations of tokens in a high-dimensional space. Each token is converted to a vector of numbers that captures its meaning and relationships to other tokens.\n",
    "\n",
    "Key properties of embeddings:\n",
    "- Similar words have similar embeddings\n",
    "- Embeddings capture semantic relationships\n",
    "- Typical dimensions: 512, 768, 1024, or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (6, 384)\n",
      "Each term is represented by 384 numbers\n",
      "\n",
      "First 10 embedding values for 'seismic inversion':\n",
      "[ 0.04884824 -0.23083036  0.63500595  0.37743944 -0.0877682  -0.79720074\n",
      " -0.5652189  -0.12953708 -0.17343518  0.01015258]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a small model for embeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer_embed = AutoTokenizer.from_pretrained(model_name)\n",
    "model_embed = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings(texts, tokenizer, model):\n",
    "    \"\"\"Get sentence embeddings\"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use CLS token embedding (first token) for sentence representation\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Get embeddings for geoscience terms\n",
    "geoscience_terms = [\n",
    "    \"seismic inversion\",\n",
    "    \"reservoir characterization\", \n",
    "    \"hydrocarbon exploration\",\n",
    "    \"petrophysical analysis\",\n",
    "    \"porosity measurement\",\n",
    "    \"permeability analysis\"\n",
    "]\n",
    "\n",
    "# Get embeddings for geoscience terms\n",
    "# Remove the hardcoded list and use the imported constant\n",
    "embeddings = get_embeddings(GEOSCIENCE_TERMS, tokenizer_embed, model_embed)\n",
    "\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Each term is represented by {embeddings.shape[1]} numbers\")\n",
    "print(f\"\\nFirst 10 embedding values for '{GEOSCIENCE_TERMS[0]}':\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872a39b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of geophysics texts: 56\n",
      "Sample texts:\n",
      "1. Seismic inversion transforms seismic reflection data into quantitative subsurface rock properties.\n",
      "2. P-wave velocity depends on rock density and bulk modulus in elastic media.\n",
      "3. S-wave velocity is controlled by shear modulus and density of the formation.\n",
      "4. Seismic amplitude variation with offset reveals fluid content and lithology changes.\n",
      "5. Pre-stack seismic inversion simultaneously estimates multiple elastic parameters from angle stacks.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model + tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# Remove the entire hardcoded geophysics_texts list and replace with:\n",
    "print(f\"Total number of geophysics texts: {len(GEOPHYSICS_TEXTS)}\")\n",
    "print(\"Sample texts:\")\n",
    "for i, text in enumerate(GEOPHYSICS_TEXTS[:5]):\n",
    "    print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b87e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([56, 384])\n",
      "Each sentence is represented by 384 dimensional vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D embeddings shape: (56, 3)\n",
      "Using perplexity: 30\n"
     ]
    }
   ],
   "source": [
    "# Encode all geophysics sentences\n",
    "inputs = tokenizer(GEOPHYSICS_TEXTS, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs).last_hidden_state[:,0,:]  # CLS token\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Each sentence is represented by {embeddings.shape[1]} dimensional vector\")\n",
    "\n",
    "# Reduce dimensions to 3D with t-SNE\n",
    "perplexity = min(30, len(GEOPHYSICS_TEXTS) - 1)\n",
    "tsne = TSNE(n_components=3, perplexity=perplexity, random_state=42, max_iter=1000)\n",
    "embeddings_3d = tsne.fit_transform(embeddings.numpy())\n",
    "\n",
    "print(f\"3D embeddings shape: {embeddings_3d.shape}\")\n",
    "print(f\"Using perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aaad5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Seismic Methods<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Seismic inversion transforms seismic reflection data into quantitative subsurface rock properties.",
          "P-wave velocity depends on rock density and bulk modulus in elastic media.",
          "S-wave velocity is controlled by shear modulus and density of the formation.",
          "Seismic amplitude variation with offset reveals fluid content and lithology changes.",
          "Pre-stack seismic inversion simultaneously estimates multiple elastic parameters from angle stacks.",
          "Post-stack seismic inversion derives acoustic impedance from normal incidence reflectivity.",
          "Seismic interpretation identifies structural features like faults, folds, and stratigraphic boundaries.",
          "Time-lapse seismic monitoring tracks reservoir changes during production and injection."
         ],
         "legendgroup": "Seismic Methods",
         "marker": {
          "color": "#636efa",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Seismic Methods",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "ZewvQaAv6EKkpZlCOZM4wn6e1cHSR6lBK33bQdhttMI=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "3DQdwpHsdsE6qMzBqchOwi3Zn0Kzt9NCEKtfwloN9r8=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "HIqGQXMNIcKytbrC+ScxwVPfRsJIYTTCD54uwqmsFsM=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Reservoir Properties<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Porosity measures the void space available for fluid storage in reservoir rocks.",
          "Permeability quantifies the ability of fluids to flow through porous rock matrices.",
          "Water saturation represents the fraction of pore space occupied by formation water.",
          "Net-to-gross ratio indicates the proportion of reservoir quality rock in a formation.",
          "Reservoir pressure drives hydrocarbon flow from formation to wellbore during production.",
          "Capillary pressure controls fluid distribution at pore scale in reservoir rocks.",
          "Relative permeability curves describe multiphase flow behavior in porous media.",
          "Formation volume factor accounts for fluid expansion from reservoir to surface conditions."
         ],
         "legendgroup": "Reservoir Properties",
         "marker": {
          "color": "#EF553B",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Reservoir Properties",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "YiFwwu3qj8KKD6lBMtddQsbbN8JbUCZDmTPOwrTNM8I=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "4kQAwpW+FUH4sjVCKuQpQR3SgELYaOBBq/KmwrPlEkI=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "z63UQrKkv8HPhPlCnv1ZQnQ8e0EaqBzDGDYTwd3oz0I=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Well Logging<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Gamma ray logs measure natural radioactivity to identify shale and clay content.",
          "Resistivity logs detect hydrocarbon presence by measuring electrical resistance of formations.",
          "Neutron logs respond to hydrogen content, indicating porosity and fluid types.",
          "Density logs measure bulk density to calculate porosity and identify lithology.",
          "Photoelectric factor from density logs helps distinguish different rock types and minerals.",
          "Spontaneous potential logs indicate permeable zones and formation water resistivity.",
          "Caliper logs measure borehole diameter to identify washouts and tight spots.",
          "Nuclear magnetic resonance logs provide pore size distribution and permeability estimates."
         ],
         "legendgroup": "Well Logging",
         "marker": {
          "color": "#00cc96",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Well Logging",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "Pir4QiGdzb/iN7tCIDadQJNalcIiNZnCqKdsQsX3gcI=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "fnYlQbON8kEvZsDC3Ga1QpZXZsJ05jJC59RrQZWXCkM=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "HXVFQhyPn8Lb+pzCouLuwpFS7sLPp67CWjsCwnZrD8I=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Drilling & Completion<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Drilling mud maintains wellbore stability and carries cuttings to surface.",
          "Casing design protects formations and enables safe drilling to target depths.",
          "Hydraulic fracturing creates artificial fractures to enhance reservoir permeability.",
          "Horizontal drilling maximizes contact with thin reservoir layers.",
          "Perforation creates communication pathways between wellbore and reservoir.",
          "Sand control prevents formation sand production that could damage equipment.",
          "Acidizing dissolves formation damage and enhances near-wellbore permeability.",
          "Wellbore trajectory optimization maximizes reservoir contact while avoiding hazards."
         ],
         "legendgroup": "Drilling & Completion",
         "marker": {
          "color": "#ab63fa",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Drilling & Completion",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "M2wSQUnZv8F2DfLCaax/wEvy7MJOxY9BRQrhwSd4CsM=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "jWI1wu753MI5V+jBvCkLQlsu68GdBAXDaTOLQWIA2UA=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "e0f0wkLZMEGAHVfCoV5UQoHDPUI0xUfCQkUJw+JmMUE=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Production Engineering<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Artificial lift systems maintain production when reservoir pressure declines.",
          "Nodal analysis optimizes production system performance from reservoir to separator.",
          "Decline curve analysis predicts future production rates and ultimate recovery.",
          "Enhanced oil recovery techniques mobilize residual oil after primary depletion.",
          "Water flooding maintains reservoir pressure and sweeps oil toward producers.",
          "Gas injection improves oil recovery through miscible or immiscible displacement.",
          "Thermal recovery methods reduce oil viscosity in heavy oil reservoirs.",
          "Production optimization balances rate, pressure, and equipment constraints."
         ],
         "legendgroup": "Production Engineering",
         "marker": {
          "color": "#FFA15A",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Production Engineering",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "fCqyQk8Mj8Gm5wZDlBaCQmQgusLcwplAUCuCQt7p1MI=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "45KVQucMy0LgWIPC08XqwmCmHEIyhvhC0xciQsPUlkI=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "JMFuwtMusULwAy1B8QWnQsv3bUJJz79BrOT+wghIHsE=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Geology & Geochemistry<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Source rock maturation generates hydrocarbons through thermal decomposition of organic matter.",
          "Migration pathways allow hydrocarbons to move from source to reservoir rocks.",
          "Structural traps accumulate hydrocarbons through folding and faulting processes.",
          "Stratigraphic traps form through depositional and diagenetic rock property changes.",
          "Seal integrity prevents hydrocarbon leakage from reservoir to surface.",
          "Basin modeling predicts hydrocarbon generation, migration, and accumulation timing.",
          "Sequence stratigraphy correlates rock units across regional geological frameworks.",
          "Diagenesis modifies reservoir quality through cementation and dissolution processes."
         ],
         "legendgroup": "Geology & Geochemistry",
         "marker": {
          "color": "#19d3f3",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Geology & Geochemistry",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "5gyOQXrU60AYO6BCn1JoQgIG4MCHvExB6qSKQluPy0I=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "xDeMwurSi8IcbjfCRWzEwsdKIcPqw5rB2uU2wlLPlEI=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "ZLQDQ0M7kUJHmslCvlPfP0Hzi0IOfMFCkLFCQU86CkE=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>color=Advanced Technologies<br>Dimension 1=%{x}<br>Dimension 2=%{y}<br>Dimension 3=%{z}<extra></extra>",
         "hovertext": [
          "Machine learning algorithms identify patterns in seismic and well log data.",
          "Digital twins create virtual reservoir models for production optimization.",
          "Microseismic monitoring tracks fracture growth during stimulation operations.",
          "Fiber optic sensing provides distributed measurements along wellbore length.",
          "Cloud computing enables large-scale reservoir simulation and data analytics.",
          "Automated drilling systems improve efficiency and reduce human error.",
          "Real-time optimization adjusts operations based on continuous data streams.",
          "Carbon capture and storage requires geological characterization for safe sequestration."
         ],
         "legendgroup": "Advanced Technologies",
         "marker": {
          "color": "#FF6692",
          "opacity": 0.7,
          "size": 5,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Advanced Technologies",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "KlvmQTtJTMIuJ2vA2ZcwwjjopsJIbnfCNAh6QiTtFcI=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "xG5iQlJnHMGN3VzAu1rbwpsCzEITJcPCgCS/QlDyDsI=",
          "dtype": "f4"
         },
         "z": {
          "bdata": "3zvVvzB0MUItRc3BnHWewl4jkEKwT2ZCrkWUQuZskcI=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "font": {
         "family": "monospace"
        },
        "height": 700,
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "Dimension 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "Dimension 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "Dimension 3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Interactive 3D Geophysics Text Embeddings"
        },
        "width": 900
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "# Create the 3D scatter plot using imported data\n",
    "fig = px.scatter_3d(\n",
    "    x=embeddings_3d[:,0],\n",
    "    y=embeddings_3d[:,1],\n",
    "    z=embeddings_3d[:,2],\n",
    "    hover_name=GEOPHYSICS_TEXTS,  # Use imported data\n",
    "    color=GEOPHYSICS_CATEGORIES,  # Use imported categories\n",
    "    title=\"Interactive 3D Geophysics Text Embeddings\",\n",
    "    labels={'x':'Dimension 1', 'y':'Dimension 2', 'z':'Dimension 3'},\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "fig.update_layout(\n",
    "    template='plotly_dark', font_family='monospace', width=900, height=700)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b402491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Similar Sentence Pairs:\n",
      "================================================================================\n",
      "Similarity: 0.905 | Same Category: âœ“\n",
      "1. [Drilling & Completion] Perforation creates communication pathways between...\n",
      "2. [Drilling & Completion] Wellbore trajectory optimization maximizes reservo...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.892 | Same Category: âœ“\n",
      "1. [Reservoir Properties] Porosity measures the void space available for flu...\n",
      "2. [Reservoir Properties] Capillary pressure controls fluid distribution at ...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.874 | Same Category: âœ“\n",
      "1. [Geology & Geochemistry] Migration pathways allow hydrocarbons to move from...\n",
      "2. [Geology & Geochemistry] Seal integrity prevents hydrocarbon leakage from r...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.866 | Same Category: âœ“\n",
      "1. [Seismic Methods] Pre-stack seismic inversion simultaneously estimat...\n",
      "2. [Seismic Methods] Post-stack seismic inversion derives acoustic impe...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.864 | Same Category: âœ“\n",
      "1. [Geology & Geochemistry] Migration pathways allow hydrocarbons to move from...\n",
      "2. [Geology & Geochemistry] Basin modeling predicts hydrocarbon generation, mi...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.864 | Same Category: âœ“\n",
      "1. [Production Engineering] Enhanced oil recovery techniques mobilize residual...\n",
      "2. [Production Engineering] Gas injection improves oil recovery through miscib...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.862 | Same Category: âœ“\n",
      "1. [Geology & Geochemistry] Stratigraphic traps form through depositional and ...\n",
      "2. [Geology & Geochemistry] Sequence stratigraphy correlates rock units across...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.854 | Same Category: âœ“\n",
      "1. [Reservoir Properties] Permeability quantifies the ability of fluids to f...\n",
      "2. [Reservoir Properties] Relative permeability curves describe multiphase f...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.854 | Same Category: âœ—\n",
      "1. [Reservoir Properties] Net-to-gross ratio indicates the proportion of res...\n",
      "2. [Geology & Geochemistry] Migration pathways allow hydrocarbons to move from...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.847 | Same Category: âœ“\n",
      "1. [Geology & Geochemistry] Source rock maturation generates hydrocarbons thro...\n",
      "2. [Geology & Geochemistry] Migration pathways allow hydrocarbons to move from...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Average similarity within same category: 0.702\n",
      "Average similarity between different categories: 0.624\n",
      "Difference: 0.078\n"
     ]
    }
   ],
   "source": [
    "# Analyze semantic similarities within categories\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings.numpy())\n",
    "\n",
    "# Find most similar sentence pairs\n",
    "similarity_pairs = []\n",
    "for i in range(len(GEOPHYSICS_TEXTS)):\n",
    "    for j in range(i+1, len(GEOPHYSICS_TEXTS)):\n",
    "        similarity_pairs.append({\n",
    "            'text1': GEOPHYSICS_TEXTS[i][:50] + '...',\n",
    "            'text2': GEOPHYSICS_TEXTS[j][:50] + '...',\n",
    "            'category1': GEOPHYSICS_CATEGORIES[i],\n",
    "            'category2': GEOPHYSICS_CATEGORIES[j],\n",
    "            'similarity': similarity_matrix[i, j],\n",
    "            'same_category': GEOPHYSICS_CATEGORIES[i] == GEOPHYSICS_CATEGORIES[j]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and sort by similarity\n",
    "df_similarities = pd.DataFrame(similarity_pairs)\n",
    "df_top_similar = df_similarities.nlargest(10, 'similarity')\n",
    "\n",
    "print(\"Top 10 Most Similar Sentence Pairs:\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in df_top_similar.iterrows():\n",
    "    same_cat = \"âœ“\" if row['same_category'] else \"âœ—\"\n",
    "    print(f\"Similarity: {row['similarity']:.3f} | Same Category: {same_cat}\")\n",
    "    print(f\"1. [{row['category1']}] {row['text1']}\")\n",
    "    print(f\"2. [{row['category2']}] {row['text2']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate average similarity within vs between categories\n",
    "within_category_sim = df_similarities[df_similarities['same_category']]['similarity'].mean()\n",
    "between_category_sim = df_similarities[~df_similarities['same_category']]['similarity'].mean()\n",
    "\n",
    "print(f\"\\nAverage similarity within same category: {within_category_sim:.3f}\")\n",
    "print(f\"Average similarity between different categories: {between_category_sim:.3f}\")\n",
    "print(f\"Difference: {within_category_sim - between_category_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56368ac5",
   "metadata": {},
   "source": [
    "## 3. Understanding Context Windows\n",
    "\n",
    "**Context window** refers to the maximum number of tokens a model can process at once. This is a crucial limitation that affects:\n",
    "- How much text the model can \"remember\"\n",
    "- The maximum input size for generation tasks\n",
    "- Computational requirements\n",
    "\n",
    "Common context window sizes:\n",
    "- GPT-2: 1,024 tokens\n",
    "- GPT-3: 4,096 tokens  \n",
    "- GPT-4: 8,192 - 32,768 tokens\n",
    "- Claude: 100,000+ tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate context window limitations\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load GPT-2 model\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set pad token\n",
    "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
    "\n",
    "print(f\"GPT-2 maximum position embeddings: {model_gpt2.config.n_positions}\")\n",
    "print(f\"This means the context window is {model_gpt2.config.n_positions} tokens\")\n",
    "\n",
    "# Create a long geoscience text to test context limits\n",
    "long_text = \"\"\"\n",
    "Seismic inversion is a geophysical technique used to derive subsurface properties from seismic data. \n",
    "The process involves converting seismic reflection data into quantitative rock and fluid properties such as \n",
    "acoustic impedance, porosity, and lithology. This technique is fundamental in hydrocarbon exploration \n",
    "and reservoir characterization. The inversion process typically starts with seismic data acquisition, \n",
    "followed by data processing, and finally the inversion itself. There are several types of seismic inversion \n",
    "including post-stack inversion, pre-stack inversion, and simultaneous inversion. Post-stack inversion \n",
    "works with stacked seismic data to derive acoustic impedance. Pre-stack inversion uses angle-dependent \n",
    "reflectivity information to derive multiple elastic properties. Simultaneous inversion integrates seismic \n",
    "and well log data to provide more accurate and detailed subsurface models.\n",
    "\"\"\" * 10  # Repeat to make it longer\n",
    "\n",
    "# Tokenize the long text\n",
    "tokens = tokenizer_gpt2.tokenize(long_text)\n",
    "print(f\"\\nLong text has {len(tokens)} tokens\")\n",
    "print(f\"Exceeds context window: {len(tokens) > model_gpt2.config.n_positions}\")\n",
    "\n",
    "# Show what happens when we truncate\n",
    "max_length = model_gpt2.config.n_positions - 50  # Leave room for generation\n",
    "truncated_tokens = tokens[:max_length]\n",
    "print(f\"Truncated to {len(truncated_tokens)} tokens for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e6952",
   "metadata": {},
   "source": [
    "## 4. Loading a Small HuggingFace Model\n",
    "\n",
    "Let's load and explore a small language model suitable for text generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d2976d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67812bfb70cf4463b69fc84c2d124ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcdf2ea1a1145c2acf5ff49f8060cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76519646b1f40028ee5f9390461ecb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70721aab471c4e84bcd0086af9daf049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafd8deb407447c7a535308e23d6ce75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2413d012aa4b0298531443bd6d7691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Smaller, faster version of GPT-2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tokenizer_gen \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 6\u001b[0m model_gen \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set pad token\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_gen\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/modeling_utils.py:317\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/modeling_utils.py:4923\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4914\u001b[0m     gguf_file\n\u001b[1;32m   4915\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4917\u001b[0m ):\n\u001b[1;32m   4918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4919\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4921\u001b[0m     )\n\u001b[0;32m-> 4923\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4925\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4936\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4941\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4943\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4944\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/modeling_utils.py:1179\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   1178\u001b[0m     }\n\u001b[0;32m-> 1179\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/utils/hub.py:321\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    264\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    265\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    267\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         snapshot_download(\n\u001b[1;32m    495\u001b[0m             path_or_repo_id,\n\u001b[1;32m    496\u001b[0m             allow_patterns\u001b[38;5;241m=\u001b[39mfull_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    506\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:624\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    613\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[38;5;241m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(â€¦)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    616\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    617\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    622\u001b[0m )\n\u001b[0;32m--> 624\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_cm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mprogress_updater\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.12/site-packages/tqdm/std.py:1138\u001b[0m, in \u001b[0;36mtqdm.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load a small, efficient model for text generation\n",
    "model_name = \"distilgpt2\"  # Smaller, faster version of GPT-2\n",
    "tokenizer_gen = AutoTokenizer.from_pretrained(model_name)\n",
    "model_gen = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set pad token\n",
    "if tokenizer_gen.pad_token is None:\n",
    "    tokenizer_gen.pad_token = tokenizer_gen.eos_token\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Vocabulary size: {tokenizer_gen.vocab_size:,}\")\n",
    "print(f\"Model parameters: {model_gen.num_parameters():,}\")\n",
    "print(f\"Context window: {model_gen.config.n_positions} tokens\")\n",
    "print(f\"Embedding dimension: {model_gen.config.n_embd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664990a",
   "metadata": {},
   "source": [
    "## 5. Generate Simple Text Completions\n",
    "\n",
    "Now let's use our model to generate text completions with various prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45267a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, tokenizer, model, max_length=100, temperature=0.7, num_return_sequences=1):\n",
    "    \"\"\"Generate text completion given a prompt\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=2  # Avoid repetition\n",
    "        )\n",
    "    \n",
    "    generated_texts = []\n",
    "    for output in outputs:\n",
    "        generated_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        generated_texts.append(generated_text)\n",
    "    \n",
    "    return generated_texts\n",
    "\n",
    "# Test with simple prompts\n",
    "simple_prompts = [\n",
    "    \"The geology of this region\",\n",
    "    \"Oil and gas exploration requires\",\n",
    "    \"Seismic waves travel through\"\n",
    "]\n",
    "\n",
    "print(\"=== Simple Text Completions ===\")\n",
    "for prompt in simple_prompts:  # Use imported prompts\n",
    "    generated = generate_text(prompt, tokenizer_gen, model_gen, max_length=60)\n",
    "    print(f\"\\nPrompt: '{prompt}'\")\n",
    "    print(f\"Completion: '{generated[0]}'\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different generation parameters\n",
    "prompt = \"Reservoir characterization involves\"\n",
    "\n",
    "print(\"=== Effect of Different Parameters ===\")\n",
    "print(f\"Prompt: '{prompt}'\\n\")\n",
    "\n",
    "# Low temperature (more deterministic)\n",
    "low_temp = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=0.3)\n",
    "print(f\"Low temperature (0.3): {low_temp[0]}\")\n",
    "\n",
    "# High temperature (more creative)\n",
    "high_temp = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=1.2)\n",
    "print(f\"High temperature (1.2): {high_temp[0]}\")\n",
    "\n",
    "# Multiple generations\n",
    "multiple = generate_text(prompt, tokenizer_gen, model_gen, max_length=50, temperature=0.8, num_return_sequences=3)\n",
    "print(\"\\nMultiple generations:\")\n",
    "for i, gen in enumerate(multiple, 1):\n",
    "    print(f\"{i}. {gen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465cd37f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we covered:\n",
    "\n",
    "1. **Tokens**: Basic units that LLMs process (words, subwords, punctuation)\n",
    "2. **Embeddings**: Numerical representations that capture semantic meaning\n",
    "3. **Context Windows**: Maximum input size limitations (1,024 tokens for GPT-2)\n",
    "4. **Model Loading**: Using HuggingFace transformers to load pre-trained models\n",
    "5. **Text Generation**: Creating completions with different parameters\n",
    "6. **Geoscience Applications**: Generating definitions for technical terms\n",
    "\n",
    "### Key Takeaways:\n",
    "- Tokenization breaks text into processable units\n",
    "- Embeddings capture semantic relationships between concepts\n",
    "- Context windows limit how much text models can process at once\n",
    "- Different prompting strategies can yield different results\n",
    "- Temperature controls randomness in generation\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with larger models for better geoscience definitions\n",
    "- Try fine-tuning models on domain-specific geoscience text\n",
    "- Explore retrieval-augmented generation (RAG) for factual accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
